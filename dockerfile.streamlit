# Dockerfile.streamlit
# Having Separate Dockerfiles for UI and FastAPI avoids mixing UI logic with backend logic.

# makes builds work across different architectures (
FROM --platform=$BUILDPLATFORM python:3.11-slim

ENV PYTHONUNBUFFERED=1 PIP_NO_CACHE_DIR=1
WORKDIR /app

# Install uv and project deps (from pyproject.toml)
COPY pyproject.toml uv.lock* ./
RUN pip install --no-cache-dir uv \
 && uv pip install --system .

# Copy the app (and data needed by the app)
COPY . .

# Explicitly copy model (in case .dockerignore excluded mlruns)
# NOTE: destination changed to /app/src/serving/model to match inference.py's path
COPY src/serving/model /app/src/serving/model

# Copy MLflow run (artifacts + metadata) to the flat /app/model convenience path
COPY src/serving/model/49b0b2861e544aa98a64014b37c12022/artifacts/model /app/model
COPY src/serving/model/49b0b2861e544aa98a64014b37c12022/artifacts/feature_columns.txt /app/model/feature_columns.txt
COPY src/serving/model/49b0b2861e544aa98a64014b37c12022/artifacts/preprocessing.pkl /app/model/preprocessing.pkl

# Streamlit config
ENV STREAMLIT_SERVER_PORT=8501 \
    STREAMLIT_SERVER_ADDRESS=0.0.0.0 \
    STREAMLIT_SERVER_BASEURLPATH=/dashboard \
    STREAMLIT_BROWSER_GATHERUSAGESTATS=false \
    API_URL=http://fastapi-backend:8000/predict


EXPOSE 8501

# Make absolutely sure Streamlit is the thing that starts
ENTRYPOINT ["streamlit", "run", "app.py"]
CMD ["--server.port=8501", "--server.address=0.0.0.0", "--server.baseUrlPath=/dashboard"]